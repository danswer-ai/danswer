version: '3'
services:
  api_server:
    #image: danswer/danswer-backend:latest
    image: docudive/api_server:v1
    build:
      context: ../../backend
      dockerfile: Dockerfile
    platform: linux/amd64  
    command: >
      /bin/sh -c "cp -r /code/danswer/* /app/danswer &&
      cp -r /code/shared_configs/* /app/shared_configs &&
      cp -r /code/alembic/* /app/alembic &&
      cp -r /code/alembic.ini /app/alembic.ini &&
      alembic upgrade head &&
      echo \"Starting Danswer Api Server\" &&
      exec uvicorn danswer.main:app --host 0.0.0.0 --port 8080"
    depends_on:
      - relational_db
      - index
      - inference_model_server
    restart: always
    ports:
      - "8080:8080"
    environment:
      # Auth Settings
      - AUTH_TYPE=${AUTH_TYPE:-disabled}
      - SESSION_EXPIRE_TIME_SECONDS=${SESSION_EXPIRE_TIME_SECONDS:-86400}
      - ENCRYPTION_KEY_SECRET=${ENCRYPTION_KEY_SECRET:-}
      - VALID_EMAIL_DOMAINS=${VALID_EMAIL_DOMAINS:-}
      - GOOGLE_OAUTH_CLIENT_ID=${GOOGLE_OAUTH_CLIENT_ID:-}
      - GOOGLE_OAUTH_CLIENT_SECRET=${GOOGLE_OAUTH_CLIENT_SECRET:-}
      - REQUIRE_EMAIL_VERIFICATION=${REQUIRE_EMAIL_VERIFICATION:-}
      - SMTP_SERVER=${SMTP_SERVER:-}  # For sending verification emails, if unspecified then defaults to 'smtp.gmail.com'
      - SMTP_PORT=${SMTP_PORT:-587}  # For sending verification emails, if unspecified then defaults to '587'
      - SMTP_USER=${SMTP_USER:-}
      - SMTP_PASS=${SMTP_PASS:-}
      - EMAIL_FROM=${EMAIL_FROM:-}
      - OAUTH_CLIENT_ID=${OAUTH_CLIENT_ID:-}
      - OAUTH_CLIENT_SECRET=${OAUTH_CLIENT_SECRET:-}
      - OPENID_CONFIG_URL=${OPENID_CONFIG_URL:-}
      # Gen AI Settings
      - GEN_AI_MODEL_PROVIDER=${GEN_AI_MODEL_PROVIDER:-}
      - GEN_AI_MODEL_VERSION=${GEN_AI_MODEL_VERSION:-}
      - FAST_GEN_AI_MODEL_VERSION=${FAST_GEN_AI_MODEL_VERSION:-}
      - GEN_AI_API_KEY=${GEN_AI_API_KEY:-}
      - GEN_AI_API_ENDPOINT=${GEN_AI_API_ENDPOINT:-}
      - GEN_AI_API_VERSION=${GEN_AI_API_VERSION:-}
      - GEN_AI_LLM_PROVIDER_TYPE=${GEN_AI_LLM_PROVIDER_TYPE:-}
      - GEN_AI_MAX_TOKENS=${GEN_AI_MAX_TOKENS:-}
      - QA_TIMEOUT=${QA_TIMEOUT:-}
      - MAX_CHUNKS_FED_TO_CHAT=${MAX_CHUNKS_FED_TO_CHAT:-}
      - DISABLE_LLM_FILTER_EXTRACTION=${DISABLE_LLM_FILTER_EXTRACTION:-}
      - DISABLE_LLM_CHUNK_FILTER=${DISABLE_LLM_CHUNK_FILTER:-}
      - DISABLE_LLM_CHOOSE_SEARCH=${DISABLE_LLM_CHOOSE_SEARCH:-}
      - DISABLE_LLM_QUERY_REPHRASE=${DISABLE_LLM_QUERY_REPHRASE:-}
      - DISABLE_GENERATIVE_AI=${DISABLE_GENERATIVE_AI:-}
      - DISABLE_LITELLM_STREAMING=${DISABLE_LITELLM_STREAMING:-}
      - LITELLM_EXTRA_HEADERS=${LITELLM_EXTRA_HEADERS:-}
      - BING_API_KEY=${BING_API_KEY:-}
      # if set, allows for the use of the token budget system
      - TOKEN_BUDGET_GLOBALLY_ENABLED=${TOKEN_BUDGET_GLOBALLY_ENABLED:-}
      # Enables the use of bedrock models
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-}
      - AWS_REGION_NAME=${AWS_REGION_NAME:-}
      # Query Options
      - DOC_TIME_DECAY=${DOC_TIME_DECAY:-}  # Recency Bias for search results, decay at 1 / (1 + DOC_TIME_DECAY * x years)
      - HYBRID_ALPHA=${HYBRID_ALPHA:-}  # Hybrid Search Alpha (0 for entirely keyword, 1 for entirely vector)
      - EDIT_KEYWORD_QUERY=${EDIT_KEYWORD_QUERY:-}
      - MULTILINGUAL_QUERY_EXPANSION=${MULTILINGUAL_QUERY_EXPANSION:-}
      - LANGUAGE_HINT=${LANGUAGE_HINT:-}
      - LANGUAGE_CHAT_NAMING_HINT=${LANGUAGE_CHAT_NAMING_HINT:-}
      - QA_PROMPT_OVERRIDE=${QA_PROMPT_OVERRIDE:-}
      # Other services
      - POSTGRES_HOST=relational_db      
      - VESPA_HOST=index
      - WEB_DOMAIN=${WEB_DOMAIN:-}  # For frontend redirect auth purpose
      # Don't change the NLP model configs unless you know what you're doing
      - DOCUMENT_ENCODER_MODEL=${DOCUMENT_ENCODER_MODEL:-}
      - DOC_EMBEDDING_DIM=${DOC_EMBEDDING_DIM:-}
      - NORMALIZE_EMBEDDINGS=${NORMALIZE_EMBEDDINGS:-}
      - ASYM_QUERY_PREFIX=${ASYM_QUERY_PREFIX:-}
      - ENABLE_RERANKING_REAL_TIME_FLOW=${ENABLE_RERANKING_REAL_TIME_FLOW:-}
      - ENABLE_RERANKING_ASYNC_FLOW=${ENABLE_RERANKING_ASYNC_FLOW:-}
      - MODEL_SERVER_HOST=${MODEL_SERVER_HOST:-inference_model_server}
      - MODEL_SERVER_PORT=${MODEL_SERVER_PORT:-}
      # Leave this on pretty please? Nothing sensitive is collected!
      # https://docs.danswer.dev/more/telemetry
      - DISABLE_TELEMETRY=${DISABLE_TELEMETRY:-}
      - LOG_LEVEL=${LOG_LEVEL:-info}  # Set to debug to get more fine-grained logs
      - LOG_ALL_MODEL_INTERACTIONS=${LOG_ALL_MODEL_INTERACTIONS:-}  # Log all of the prompts to the LLM
      # If set to `true` will enable additional logs about Vespa query performance
      # (time spent on finding the right docs + time spent fetching summaries from disk)
      - LOG_VESPA_TIMING_INFORMATION=${LOG_VESPA_TIMING_INFORMATION:-}
      - LOG_ENDPOINT_LATENCY=${LOG_ENDPOINT_LATENCY:-}

      # Enterprise Edition only
      - ENABLE_PAID_ENTERPRISE_EDITION_FEATURES=${ENABLE_PAID_ENTERPRISE_EDITION_FEATURES:-false}
      - API_KEY_HASH_ROUNDS=${API_KEY_HASH_ROUNDS:-}
      # Seeding configuration
      - ENV_SEED_CONFIGURATION=${ENV_SEED_CONFIGURATION:-}
      - LANGFUSE_SECRET_KEY=${LANGFUSE_SECRET_KEY:-}
      - LANGFUSE_PUBLIC_KEY=${LANGFUSE_PUBLIC_KEY:-}
      - LANGFUSE_HOST=${LANGFUSE_HOST:-}      
      # Image server config
      - IMAGE_SERVER=${IMAGE_SERVER:-192.168.1.74}
      - IMAGE_SERVER_PROTOCAL=${IMAGE_SERVER_PROTOCAL:-http}
      - IMAGE_SERVER_PORT=${IMAGE_SERVER_PORT:-9123}
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ../../backend:/code    
      - /data/spectra_data/imageserver/web/images:/images
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "6"


  background:
    #image: danswer/danswer-backend:latest
    image: docudive/background:v1    
    build:
      context: ../../backend
      dockerfile: Dockerfile
    platform: linux/amd64  
    command: > 
      /bin/sh -c "cp -r /code/danswer/* /app/danswer &&
      cp -r /code/shared_configs/* /app/shared_configs &&
      cp -r /code/alembic/* /app/alembic &&
      cp -r /code/alembic.ini /app/alembic.ini &&
      exec /usr/bin/supervisord -c /etc/supervisor/conf.d/supervisord.conf"      
    depends_on:
      - relational_db
      - index
      - inference_model_server
      - indexing_model_server
    restart: always
#    volumes:
#      - ../../backend/:/app
    environment:
      - ENCRYPTION_KEY_SECRET=${ENCRYPTION_KEY_SECRET:-}
      # Gen AI Settings (Needed by DanswerBot)
      - GEN_AI_MODEL_PROVIDER=${GEN_AI_MODEL_PROVIDER:-}
      - GEN_AI_MODEL_VERSION=${GEN_AI_MODEL_VERSION:-}
      - FAST_GEN_AI_MODEL_VERSION=${FAST_GEN_AI_MODEL_VERSION:-}
      - GEN_AI_API_KEY=${GEN_AI_API_KEY:-}
      - GEN_AI_API_ENDPOINT=${GEN_AI_API_ENDPOINT:-}
      - GEN_AI_API_VERSION=${GEN_AI_API_VERSION:-}
      - GEN_AI_LLM_PROVIDER_TYPE=${GEN_AI_LLM_PROVIDER_TYPE:-}
      - GEN_AI_MAX_TOKENS=${GEN_AI_MAX_TOKENS:-}
      - QA_TIMEOUT=${QA_TIMEOUT:-}
      - MAX_CHUNKS_FED_TO_CHAT=${MAX_CHUNKS_FED_TO_CHAT:-}
      - DISABLE_LLM_FILTER_EXTRACTION=${DISABLE_LLM_FILTER_EXTRACTION:-}
      - DISABLE_LLM_CHUNK_FILTER=${DISABLE_LLM_CHUNK_FILTER:-}
      - DISABLE_LLM_CHOOSE_SEARCH=${DISABLE_LLM_CHOOSE_SEARCH:-}
      - DISABLE_LLM_QUERY_REPHRASE=${DISABLE_LLM_QUERY_REPHRASE:-}
      - DISABLE_GENERATIVE_AI=${DISABLE_GENERATIVE_AI:-}
      - GENERATIVE_MODEL_ACCESS_CHECK_FREQ=${GENERATIVE_MODEL_ACCESS_CHECK_FREQ:-}
      - DISABLE_LITELLM_STREAMING=${DISABLE_LITELLM_STREAMING:-}
      - LITELLM_EXTRA_HEADERS=${LITELLM_EXTRA_HEADERS:-}
      - BING_API_KEY=${BING_API_KEY:-}
      # Query Options
      - DOC_TIME_DECAY=${DOC_TIME_DECAY:-}  # Recency Bias for search results, decay at 1 / (1 + DOC_TIME_DECAY * x years)
      - HYBRID_ALPHA=${HYBRID_ALPHA:-}  # Hybrid Search Alpha (0 for entirely keyword, 1 for entirely vector)
      - EDIT_KEYWORD_QUERY=${EDIT_KEYWORD_QUERY:-}
      - MULTILINGUAL_QUERY_EXPANSION=${MULTILINGUAL_QUERY_EXPANSION:-}
      - LANGUAGE_HINT=${LANGUAGE_HINT:-}
      - LANGUAGE_CHAT_NAMING_HINT=${LANGUAGE_CHAT_NAMING_HINT:-}
      - QA_PROMPT_OVERRIDE=${QA_PROMPT_OVERRIDE:-}
      # Other Services
      - POSTGRES_HOST=relational_db
      - POSTGRES_USER=${POSTGRES_USER:-}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-}
      - POSTGRES_DB=${POSTGRES_DB:-}
      - VESPA_HOST=index
      - WEB_DOMAIN=${WEB_DOMAIN:-}  # For frontend redirect auth purpose for OAuth2 connectors
      # Don't change the NLP model configs unless you know what you're doing
      - DOCUMENT_ENCODER_MODEL=${DOCUMENT_ENCODER_MODEL:-}
      - DOC_EMBEDDING_DIM=${DOC_EMBEDDING_DIM:-}
      - NORMALIZE_EMBEDDINGS=${NORMALIZE_EMBEDDINGS:-}
      - ASYM_QUERY_PREFIX=${ASYM_QUERY_PREFIX:-}  # Needed by DanswerBot
      - ASYM_PASSAGE_PREFIX=${ASYM_PASSAGE_PREFIX:-}
      - MODEL_SERVER_HOST=${MODEL_SERVER_HOST:-inference_model_server}
      - MODEL_SERVER_PORT=${MODEL_SERVER_PORT:-}
      - INDEXING_MODEL_SERVER_HOST=${INDEXING_MODEL_SERVER_HOST:-indexing_model_server}
      # Indexing Configs
      - NUM_INDEXING_WORKERS=${NUM_INDEXING_WORKERS:-}
      - ENABLED_CONNECTOR_TYPES=${ENABLED_CONNECTOR_TYPES:-}
      - DISABLE_INDEX_UPDATE_ON_SWAP=${DISABLE_INDEX_UPDATE_ON_SWAP:-}
      - DASK_JOB_CLIENT_ENABLED=${DASK_JOB_CLIENT_ENABLED:-}
      - CONTINUE_ON_CONNECTOR_FAILURE=${CONTINUE_ON_CONNECTOR_FAILURE:-}
      - EXPERIMENTAL_CHECKPOINTING_ENABLED=${EXPERIMENTAL_CHECKPOINTING_ENABLED:-}
      - CONFLUENCE_CONNECTOR_LABELS_TO_SKIP=${CONFLUENCE_CONNECTOR_LABELS_TO_SKIP:-}
      - JIRA_CONNECTOR_LABELS_TO_SKIP=${JIRA_CONNECTOR_LABELS_TO_SKIP:-}
      - WEB_CONNECTOR_VALIDATE_URLS=${WEB_CONNECTOR_VALIDATE_URLS:-}
      - JIRA_API_VERSION=${JIRA_API_VERSION:-}
      - GONG_CONNECTOR_START_TIME=${GONG_CONNECTOR_START_TIME:-}
      - NOTION_CONNECTOR_ENABLE_RECURSIVE_PAGE_LOOKUP=${NOTION_CONNECTOR_ENABLE_RECURSIVE_PAGE_LOOKUP:-}
      - GITHUB_CONNECTOR_BASE_URL=${GITHUB_CONNECTOR_BASE_URL:-}
      # Danswer SlackBot Configs
      - DANSWER_BOT_SLACK_APP_TOKEN=${DANSWER_BOT_SLACK_APP_TOKEN:-}
      - DANSWER_BOT_SLACK_BOT_TOKEN=${DANSWER_BOT_SLACK_BOT_TOKEN:-}
      - DANSWER_BOT_DISABLE_DOCS_ONLY_ANSWER=${DANSWER_BOT_DISABLE_DOCS_ONLY_ANSWER:-}
      - DANSWER_BOT_FEEDBACK_VISIBILITY=${DANSWER_BOT_FEEDBACK_VISIBILITY:-}
      - DANSWER_BOT_DISPLAY_ERROR_MSGS=${DANSWER_BOT_DISPLAY_ERROR_MSGS:-}
      - DANSWER_BOT_RESPOND_EVERY_CHANNEL=${DANSWER_BOT_RESPOND_EVERY_CHANNEL:-}
      - DANSWER_BOT_DISABLE_COT=${DANSWER_BOT_DISABLE_COT:-}  # Currently unused
      - NOTIFY_SLACKBOT_NO_ANSWER=${NOTIFY_SLACKBOT_NO_ANSWER:-}
      - DANSWER_BOT_MAX_QPM=${DANSWER_BOT_MAX_QPM:-}
      - DANSWER_BOT_MAX_WAIT_TIME=${DANSWER_BOT_MAX_WAIT_TIME:-}
      # Logging
      # Leave this on pretty please? Nothing sensitive is collected!
      # https://docs.danswer.dev/more/telemetry
      - DISABLE_TELEMETRY=${DISABLE_TELEMETRY:-}
      - LOG_LEVEL=${LOG_LEVEL:-info}  # Set to debug to get more fine-grained logs
      - LOG_ALL_MODEL_INTERACTIONS=${LOG_ALL_MODEL_INTERACTIONS:-}  # Log all of the prompts to the LLM
      - LOG_VESPA_TIMING_INFORMATION=${LOG_VESPA_TIMING_INFORMATION:-}
      - LANGFUSE_SECRET_KEY=${LANGFUSE_SECRET_KEY:-}
      - LANGFUSE_PUBLIC_KEY=${LANGFUSE_PUBLIC_KEY:-}
      - LANGFUSE_HOST=${LANGFUSE_HOST:-} 
      # Enterprise Edition stuff
      - ENABLE_PAID_ENTERPRISE_EDITION_FEATURES=${ENABLE_PAID_ENTERPRISE_EDITION_FEATURES:-false}
     
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ../../backend:/code      
    ports:
      - "9080:8080"
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "6"


  web_server:
    #image: danswer/danswer-web-server:latest
    image: docudive/web_server:v1
    build:
      context: ../../web
      dockerfile: Dockerfile
      args:
        - NEXT_PUBLIC_DISABLE_STREAMING=${NEXT_PUBLIC_DISABLE_STREAMING:-false}
        - NEXT_PUBLIC_NEW_CHAT_DIRECTS_TO_SAME_PERSONA=${NEXT_PUBLIC_NEW_CHAT_DIRECTS_TO_SAME_PERSONA:-false}
        - NEXT_PUBLIC_POSITIVE_PREDEFINED_FEEDBACK_OPTIONS=${NEXT_PUBLIC_POSITIVE_PREDEFINED_FEEDBACK_OPTIONS:-}
        - NEXT_PUBLIC_NEGATIVE_PREDEFINED_FEEDBACK_OPTIONS=${NEXT_PUBLIC_NEGATIVE_PREDEFINED_FEEDBACK_OPTIONS:-}
        - NEXT_PUBLIC_DISABLE_LOGOUT=${NEXT_PUBLIC_DISABLE_LOGOUT:-}

        # Enterprise Edition only
        - NEXT_PUBLIC_THEME=${NEXT_PUBLIC_THEME:-}
        # DO NOT TURN ON unless you have EXPLICIT PERMISSION from Danswer.
        - NEXT_PUBLIC_DO_NOT_USE_TOGGLE_OFF_DANSWER_POWERED=${NEXT_PUBLIC_DO_NOT_USE_TOGGLE_OFF_DANSWER_POWERED:-false}
    platform: linux/amd64    
    depends_on:
      - api_server
    restart: always
    environment:
      - INTERNAL_URL=http://api_server:8080
      - WEB_DOMAIN=${WEB_DOMAIN:-}
      - THEME_IS_DARK=${THEME_IS_DARK:-}

      # Enterprise Edition only
      - ENABLE_PAID_ENTERPRISE_EDITION_FEATURES=${ENABLE_PAID_ENTERPRISE_EDITION_FEATURES:-false}


  inference_model_server:
    #image: danswer/danswer-model-server:latest
    image: docudive/inference_server:v1
        # for GPU support, please read installation guidelines in the README.md
    # bare minimum to get this working is to install nvidia-container-toolkit
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    build:
      context: ../../backend
      dockerfile: Dockerfile.model_server
    platform: linux/amd64   
    command: >
      /bin/sh -c "if [ \"${DISABLE_MODEL_SERVER:-false}\" = \"True\" ]; then
        echo 'Skipping service...';
        exit 0;
      else
        cp -r /code/danswer/utils/logger.py /app/danswer/utils/logger.py &&
        cp -r /code/danswer/__init__.py /app/danswer/__init__.py &&
        cp -r /code/shared_configs/* /app/shared_configs && 
        cp -r /code/model_server/* /app/model_server && 
        exec uvicorn model_server.main:app --host 0.0.0.0 --port 9000;
      fi"
    restart: on-failure
    environment:
      - MIN_THREADS_ML_MODELS=${MIN_THREADS_ML_MODELS:-}
      # Set to debug to get more fine-grained logs
      - LOG_LEVEL=${LOG_LEVEL:-info}
    volumes:
      # Not necessary, this is just to reduce download time during startup
      - /data/spectra_data/model_cache_huggingface:/root/.cache/huggingface/
      - ../../backend:/code            
    ports:
      - "9090:8080"
      - "9900:9000"
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "6"


  indexing_model_server:
    #image: danswer/danswer-model-server:latest
    image: docudive/indexing_server:v1
        # for GPU support, please read installation guidelines in the README.md
    # bare minimum to get this working is to install nvidia-container-toolkit
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    build:
      context: ../../backend
      dockerfile: Dockerfile.model_server
    platform: linux/amd64   
    command: >
      /bin/sh -c "if [ \"${DISABLE_MODEL_SERVER:-false}\" = \"True\" ]; then
        echo 'Skipping service...';
        exit 0;
      else
        cp -r /code/danswer/utils/logger.py /app/danswer/utils/logger.py &&
        cp -r /code/danswer/__init__.py /app/danswer/__init__.py &&
        cp -r /code/shared_configs/* /app/shared_configs && 
        cp -r /code/model_server/* /app/model_server &&       
        exec uvicorn model_server.main:app --host 0.0.0.0 --port 9000;
      fi"
    restart: on-failure
    environment:
      - MIN_THREADS_ML_MODELS=${MIN_THREADS_ML_MODELS:-}
      - INDEXING_ONLY=True
      # Set to debug to get more fine-grained logs
      - LOG_LEVEL=${LOG_LEVEL:-info}
    volumes:
      # Not necessary, this is just to reduce download time during startup
      - /data/spectra_data/model_cache_huggingface:/root/.cache/huggingface/
      - ../../backend:/code            
    ports:
      - "7080:8080"
      - "9000:9000"      
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "6"


  relational_db:
    #image: postgres:15.2-alpine
    image: docudive/relational_db:v1
    restart: always
    platform: linux/amd64 
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-password}
    ports:
      - "5432:5432"
    volumes:
      - /data/spectra_data/db_volume:/var/lib/postgresql/data

  pgadmin:
    #container_name: pgadmin_container
    container_name: pgadmin_container
    image: dpage/pgadmin4
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL:-admin@v.com}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD:-admin}
      PGADMIN_CONFIG_SERVER_MODE: 'False'
    volumes:
       - /data/spectra_data/pgadmin:/var/lib/pgadmin

    ports:
      - "6432:80"

  # This container name cannot have an underscore in it due to Vespa expectations of the URL
  index:
    #image: vespaengine/vespa:8.277.17
    image: docudive/vespa_index:v1
    restart: always
    platform: linux/amd64 
    ports:
      - "19071:19071"
      - "8081:8081"
    volumes:
      - /data/spectra_data/vespa_volume:/opt/vespa/var
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "6"


  nginx:
    #image: nginx:1.23.4-alpine
    image: docudive/nginx:v1
    restart: always
    # nginx will immediately crash with `nginx: [emerg] host not found in upstream`
    # if api_server / web_server are not up 
    platform: linux/amd64 
    depends_on:
      - api_server
      - web_server
    environment:
      - DOMAIN=localhost
    ports:
      - "80:80"
      - "3000:80"  # allow for localhost:3000 usage, since that is the norm
    volumes:
      - ../data/nginx:/etc/nginx/conf.d
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "6"
    # The specified script waits for the api_server to start up. 
    # Without this we've seen issues where nginx shows no error logs but 
    # does not recieve any traffic
    # NOTE: we have to use dos2unix to remove Carriage Return chars from the file
    # in order to make this work on both Unix-like systems and windows
    command: > 
      /bin/sh -c "dos2unix /etc/nginx/conf.d/run-nginx.sh 
      && /etc/nginx/conf.d/run-nginx.sh app.conf.template.dev"
        
  imageserver:
    image: nginx:latest
    container_name: imageserver    
    ports:
      - "9123:80"
    volumes:
      - /data/spectra_data/imageserver/web/images:/usr/share/nginx/html/images:ro
      - ./imageserver_nginx.conf:/etc/nginx/nginx.conf:ro
      - /data/spectra_data/imageserver/logs:/var/log/nginx:rw
    restart: unless-stopped

  portainer:
    image: portainer/portainer-ce:latest
    container_name: portainer
    ports:
      - "3457:9000"
    command: -H unix:///var/run/docker.sock
    environment:
      # Set default admin username and password
      - ADMIN_USERNAME=admin
      - ADMIN_PASSWORD=yourpassword123
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /data/spectra_data/portainer_data:/data
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true  # Security best practice


  langfuse:
    #image: ghcr.io/langfuse/langfuse:latest
    image: docudive/langfuse:v1
    platform: linux/amd64   
    ports:
      - "3456:3456"
    environment:
      - DATABASE_URL=postgresql://postgres:password@relational_db:5432/langfuse
      - NEXTAUTH_URL=${NEXTAUTH_URL:-http://host.docker.internal:3456}
      - NEXTAUTH_SECRET=mysecret
      - SALT=mysalt
      - PORT=3456
      - TELEMETRY_ENABLED=false
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        
volumes:
  db_volume:
  vespa_volume:
  # Created by the container itself
  model_cache_huggingface:
